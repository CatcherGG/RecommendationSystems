{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6N98jxu7Jdqv"
   },
   "source": [
    "# Question 8\n",
    "\n",
    "## Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5QuBIjcL7J6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/1b/9ad0093cac05d6f95d3d768bc855804b18723c72120ce45cd930bd303587/xlearn-0.40a1.tar.gz (4.9MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9MB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: xlearn\n",
      "  Building wheel for xlearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for xlearn: filename=xlearn-0.40a1-cp36-none-any.whl size=226076 sha256=cc3be4ed85b941bec73dac9a8b3eb885e7f53fab6d4562b3667931858a00fc24\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/7d/71/699578f3cb69f16a2e5f648d978259dba959c92a5a6eca9451\n",
      "Successfully built xlearn\n",
      "Installing collected packages: xlearn\n",
      "Successfully installed xlearn-0.40a1\n"
     ]
    }
   ],
   "source": [
    "!pip install xlearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXONOMY_WITH_LESS_THAN_100 = set([\n",
    "    'BUSINESS~PERSONAL-FINANCE', \n",
    "    'ENTERTAINMENT~MOVIES',\n",
    "    'LIFE~ASTROLOGY',\n",
    "    'LIFE~FITNESS',\n",
    "    'SPORTS~CRICKET',\n",
    "    'TECH~WEB',\n",
    "    'TECH~SCIENCE~SPACE'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'page_view_start_time':                            'int16',\n",
    "        'user_id_hash':                                         'category',\n",
    "        'target_id_hash':                                       'category',\n",
    "        'syndicator_id_hash':                                'category',\n",
    "        'campaign_id_hash':                                 'category',\n",
    "        'empiric_calibrated_recs':                          'float16',\n",
    "        'empiric_clicks':                                          'float16',\n",
    "        'target_item_taxonomy':                             'category',\n",
    "        'placement_id_hash':                                 'category',\n",
    "        'user_recs':                                                'int16',\n",
    "        'user_clicks':                                               'int16',\n",
    "        'user_target_recs':                                      'int16',\n",
    "        'publisher_id_hash':                                   'category',\n",
    "        'source_id_hash':                                        'category',\n",
    "        'source_item_type':                                   'category',\n",
    "        'browser_platform':                                    'category',\n",
    "        'os_family':                                                 'category',\n",
    "        'country_code':                                         'category',\n",
    "        'region':                                                     'category',\n",
    "        'day_of_week':                                           'int8',\n",
    "        'time_of_day':                                             'int8',\n",
    "        'gmt_offset':                                                'int8',\n",
    "    \n",
    "#         'empiric_ctr':                                             'int8',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from csv import DictReader\n",
    "import math\n",
    "\n",
    "num_cols = ['page_view_start_time', \n",
    "                    'empiric_calibrated_recs',\n",
    "                    'empiric_clicks',\n",
    "                    'user_recs',\n",
    "                    'user_clicks',\n",
    "                    'user_target_recs',\n",
    "                    'day_of_week',\n",
    "                    'time_of_day',\n",
    "                    ]\n",
    "\n",
    "too_many_vals = []\n",
    "\n",
    "publisher_848 =  '848b127dbd0f3a647581f4a95325f5204f4577ad7956f6ccaee6bf1eec0c399e6b02015827a95741ae041adc2438fbd494076ece7796a5f6cf4eab29e1079cf3'\n",
    "publisher_c29 = 'c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f024944fbd55d0ecbec178d4fc94c38d88a56a177a1c302f47ac1293dbbed50638455d50b1769daedbd33aaf'\n",
    "publisher_f8a = 'f8a7ba9b7c9b05464ee98daac522b3f3d2376453c70e57de45b65e65a06b3b45fedd82ec18291bb4e432f3a172893424a81bab47dad1b4355b68552cda00583a'\n",
    "\n",
    "\n",
    "def create_train_test_files(max_files=68, validation_files = 8):\n",
    "    dont_use = ['page_view_start_time', 'gmt_offset']\n",
    "    categories = [k for k, v in dtypes.items() if k not in dont_use]\n",
    "    categories_index = dict(zip(categories, range(len(categories))))\n",
    "    field_features = defaultdict()\n",
    "\n",
    "    max_val = 1\n",
    "    for index, file in enumerate(glob.glob('./data/train/*.csv')):\n",
    "        if index > max_files:\n",
    "            break\n",
    "        \n",
    "        main_libffm = 'train.libffm'\n",
    "        if index > max_files - validation_files:\n",
    "            main_libffm = 'valid.libffm'\n",
    "\n",
    "        with open(main_libffm, 'a') as the_file:\n",
    "            for t, row in enumerate(DictReader(open(file))):\n",
    "                if t % 100000 == 0:\n",
    "                    print(t, len(field_features), max_val)\n",
    "\n",
    "                label = [row['is_click']]\n",
    "                ffeatures = []\n",
    "                \n",
    "                row['empiric_calibrated_recs'] = round(float(row['empiric_calibrated_recs']) / 1000) \n",
    "                if row['target_item_taxonomy'] in TAXONOMY_WITH_LESS_THAN_100:\n",
    "                    row['target_item_taxonomy'] = row['target_item_taxonomy'][:row['target_item_taxonomy'].rfind('~')]\n",
    "#                 if float(row['user_recs']) != 0:\n",
    "#                     row['user_ctr'] = float(row['user_clicks']) / float(row['user_recs'])\n",
    "#                 else:\n",
    "#                     row['user_ctr'] = -1\n",
    "                \n",
    "                for field in categories:\n",
    "                    if field == 'is_click':\n",
    "                        continue\n",
    "                    feature = row[field]\n",
    "\n",
    "                    if feature == '':\n",
    "                        feature = \"unk\"\n",
    "                    if field not in num_cols:\n",
    "                        ff = field + '_____' + feature\n",
    "                    else:\n",
    "                        if feature == \"unk\" or float(feature) == -1:\n",
    "                            ff = field + '_____' + str(0)\n",
    "                        else:\n",
    "                            if field in too_many_vals:\n",
    "                                ff = field + '_____' + str(int(round(math.log(1 + float(feature)))))\n",
    "                            else:\n",
    "                                ff = field + '_____' + str(int(round(float(feature))))\n",
    "                    if ff not in field_features:\n",
    "                        if len(field_features) == 0:\n",
    "                            field_features[ff] = 1\n",
    "                            max_val += 1\n",
    "                        else:\n",
    "                            field_features[ff] = max_val + 1\n",
    "                            max_val += 1\n",
    "\n",
    "                    fnum = field_features[ff]\n",
    "                    ffeatures.append('{}:{}:1'.format(categories_index[field], fnum))\n",
    "\n",
    "                \n",
    "                line = label + ffeatures\n",
    "                the_file.write('{}\\n'.format(' '.join(line)))\n",
    "\n",
    "                \n",
    "    train_path = './data/test_file_v3/test_file.csv'\n",
    "    with open('test.libffm', 'a') as the_file:\n",
    "        for t, row in enumerate(DictReader(open(train_path))):\n",
    "            if t % 100000 == 0:\n",
    "                print(t, len(field_features), max_val)\n",
    "\n",
    "            label = ['0']\n",
    "            ffeatures = []\n",
    "\n",
    "            row['empiric_calibrated_recs'] = round(float(row['empiric_calibrated_recs']) / 1000)\n",
    "            if row['target_item_taxonomy'] in TAXONOMY_WITH_LESS_THAN_100:\n",
    "                row['target_item_taxonomy'] = row['target_item_taxonomy'][:row['target_item_taxonomy'].rfind('~')]\n",
    "                    \n",
    "            for field in categories:\n",
    "                if field == 'is_click':\n",
    "                    continue\n",
    "                feature = row[field]\n",
    "                if feature == '':\n",
    "                    feature = \"unk\"\n",
    "                if field not in num_cols:\n",
    "                    ff = field + '_____' + feature\n",
    "                else:\n",
    "                    if feature == \"unk\" or float(feature) == -1:\n",
    "                        ff = field + '_____' + str(0)\n",
    "                    else:\n",
    "                        if field in too_many_vals:\n",
    "                            ff = field + '_____' + str(int(round(math.log(1 + float(feature)))))\n",
    "                        else:\n",
    "                            ff = field + '_____' + str(int(round(float(feature))))\n",
    "                if ff not in field_features:\n",
    "                    if len(field_features) == 0:\n",
    "                        field_features[ff] = 1\n",
    "                        max_val += 1\n",
    "                    else:\n",
    "                        field_features[ff] = max_val + 1\n",
    "                        max_val += 1\n",
    "\n",
    "                fnum = field_features[ff]\n",
    "\n",
    "                ffeatures.append('{}:{}:1'.format(categories_index[field], fnum))\n",
    "            line = label + ffeatures\n",
    "            the_file.write('{}\\n'.format(' '.join(line)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1\n",
      "100000 169846 169847\n",
      "200000 291707 291708\n",
      "300000 405119 405120\n",
      "400000 513581 513582\n",
      "0 580069 580070\n",
      "100000 683662 683663\n",
      "200000 785183 785184\n",
      "300000 884634 884635\n",
      "400000 982609 982610\n",
      "0 1014645 1014646\n",
      "100000 1110859 1110860\n",
      "200000 1205666 1205667\n",
      "300000 1299551 1299552\n",
      "400000 1392071 1392072\n",
      "0 1410622 1410623\n",
      "100000 1501870 1501871\n",
      "200000 1592348 1592349\n",
      "300000 1681717 1681718\n",
      "400000 1770440 1770441\n",
      "0 1814399 1814400\n",
      "100000 1901368 1901369\n",
      "200000 1987852 1987853\n",
      "300000 2073502 2073503\n",
      "400000 2158438 2158439\n",
      "0 2174487 2174488\n",
      "100000 2258819 2258820\n",
      "200000 2342164 2342165\n",
      "300000 2424959 2424960\n",
      "400000 2507147 2507148\n",
      "0 2541261 2541262\n",
      "100000 2622408 2622409\n",
      "200000 2703068 2703069\n",
      "300000 2782945 2782946\n",
      "400000 2862074 2862075\n",
      "0 2898437 2898438\n",
      "100000 2976946 2976947\n",
      "200000 3055022 3055023\n",
      "300000 3132554 3132555\n",
      "400000 3209514 3209515\n",
      "0 3268651 3268652\n",
      "100000 3344727 3344728\n",
      "200000 3420326 3420327\n",
      "300000 3495269 3495270\n",
      "400000 3570152 3570153\n",
      "0 3601972 3601973\n",
      "100000 3676254 3676255\n",
      "200000 3749694 3749695\n",
      "300000 3822865 3822866\n",
      "400000 3895627 3895628\n",
      "0 3922730 3922731\n",
      "100000 3994849 3994850\n",
      "200000 4066783 4066784\n",
      "300000 4137937 4137938\n",
      "400000 4208805 4208806\n",
      "0 4235198 4235199\n",
      "100000 4305708 4305709\n",
      "200000 4376188 4376189\n",
      "300000 4445770 4445771\n",
      "400000 4515000 4515001\n",
      "0 4564476 4564477\n",
      "100000 4633456 4633457\n",
      "200000 4701893 4701894\n",
      "300000 4769836 4769837\n",
      "400000 4837697 4837698\n",
      "0 4862671 4862672\n",
      "100000 4930111 4930112\n",
      "200000 4997221 4997222\n",
      "300000 5063598 5063599\n",
      "400000 5129847 5129848\n",
      "0 5153523 5153524\n",
      "100000 5219545 5219546\n",
      "200000 5285152 5285153\n",
      "300000 5350325 5350326\n",
      "400000 5415452 5415453\n",
      "0 5440482 5440483\n",
      "100000 5505085 5505086\n",
      "200000 5569531 5569532\n",
      "300000 5633663 5633664\n",
      "400000 5697765 5697766\n",
      "0 5734270 5734271\n",
      "100000 5797667 5797668\n",
      "200000 5860756 5860757\n",
      "300000 5924013 5924014\n",
      "400000 5986696 5986697\n",
      "0 6002935 6002936\n",
      "100000 6065386 6065387\n",
      "200000 6127421 6127422\n",
      "300000 6189420 6189421\n",
      "400000 6250979 6250980\n",
      "0 6269193 6269194\n",
      "100000 6330481 6330482\n",
      "200000 6391684 6391685\n",
      "300000 6452704 6452705\n",
      "400000 6513566 6513567\n",
      "0 6548649 6548650\n",
      "100000 6608965 6608966\n",
      "200000 6669149 6669150\n",
      "300000 6729040 6729041\n",
      "400000 6788720 6788721\n",
      "0 6817509 6817510\n",
      "100000 6877001 6877002\n",
      "200000 6936329 6936330\n",
      "300000 6995497 6995498\n",
      "400000 7054005 7054006\n",
      "0 7066450 7066451\n",
      "100000 7125081 7125082\n",
      "200000 7183764 7183765\n",
      "300000 7241832 7241833\n",
      "400000 7300091 7300092\n",
      "0 7319784 7319785\n",
      "100000 7377620 7377621\n",
      "200000 7435355 7435356\n",
      "300000 7492589 7492590\n",
      "400000 7549538 7549539\n",
      "0 7565970 7565971\n",
      "100000 7622638 7622639\n",
      "200000 7679134 7679135\n",
      "300000 7735524 7735525\n",
      "400000 7792003 7792004\n",
      "0 7817100 7817101\n",
      "100000 7873390 7873391\n",
      "200000 7929369 7929370\n",
      "300000 7985407 7985408\n",
      "400000 8040949 8040950\n",
      "0 8064806 8064807\n",
      "100000 8120113 8120114\n",
      "200000 8175391 8175392\n",
      "300000 8230453 8230454\n",
      "400000 8285394 8285395\n",
      "0 8300900 8300901\n",
      "100000 8355578 8355579\n",
      "200000 8410046 8410047\n",
      "300000 8464770 8464771\n",
      "400000 8518865 8518866\n",
      "0 8557571 8557572\n",
      "100000 8611684 8611685\n",
      "200000 8665465 8665466\n",
      "300000 8719205 8719206\n",
      "400000 8772456 8772457\n",
      "0 8808129 8808130\n",
      "100000 8861522 8861523\n",
      "200000 8914817 8914818\n",
      "300000 8967993 8967994\n",
      "0 9019536 9019537\n",
      "100000 9071949 9071950\n",
      "200000 9124732 9124733\n",
      "300000 9177280 9177281\n",
      "400000 9229415 9229416\n",
      "0 9245776 9245777\n",
      "100000 9297899 9297900\n",
      "200000 9349954 9349955\n",
      "300000 9401429 9401430\n",
      "400000 9453117 9453118\n",
      "0 9484820 9484821\n",
      "100000 9536429 9536430\n",
      "200000 9587812 9587813\n",
      "300000 9638920 9638921\n",
      "400000 9690180 9690181\n",
      "0 9696053 9696054\n",
      "100000 9747164 9747165\n",
      "200000 9798095 9798096\n",
      "300000 9848812 9848813\n",
      "400000 9899410 9899411\n",
      "0 9926457 9926458\n",
      "100000 9977006 9977007\n",
      "200000 10027361 10027362\n",
      "300000 10077342 10077343\n",
      "400000 10127183 10127184\n",
      "0 10150680 10150681\n",
      "100000 10200838 10200839\n",
      "200000 10250460 10250461\n",
      "300000 10300127 10300128\n",
      "400000 10349387 10349388\n",
      "0 10360479 10360480\n",
      "100000 10409924 10409925\n",
      "200000 10459098 10459099\n",
      "300000 10508309 10508310\n",
      "400000 10557103 10557104\n",
      "0 10574014 10574015\n",
      "100000 10622748 10622749\n",
      "200000 10671499 10671500\n",
      "300000 10720277 10720278\n",
      "400000 10768837 10768838\n",
      "0 10793179 10793180\n",
      "100000 10841586 10841587\n",
      "200000 10889610 10889611\n",
      "300000 10937630 10937631\n",
      "400000 10985685 10985686\n",
      "0 11011934 11011935\n",
      "100000 11059649 11059650\n",
      "200000 11107402 11107403\n",
      "300000 11154798 11154799\n",
      "400000 11202700 11202701\n",
      "0 11227268 11227269\n",
      "100000 11275049 11275050\n",
      "200000 11322549 11322550\n",
      "300000 11369878 11369879\n",
      "400000 11416951 11416952\n",
      "0 11435426 11435427\n",
      "100000 11482352 11482353\n",
      "200000 11529532 11529533\n",
      "300000 11576516 11576517\n",
      "400000 11623284 11623285\n",
      "0 11638688 11638689\n",
      "100000 11685303 11685304\n",
      "200000 11731805 11731806\n",
      "300000 11778243 11778244\n",
      "400000 11824843 11824844\n",
      "0 11831922 11831923\n",
      "100000 11878115 11878116\n",
      "200000 11924338 11924339\n",
      "300000 11970278 11970279\n",
      "400000 12016135 12016136\n",
      "0 12036620 12036621\n",
      "100000 12082777 12082778\n",
      "200000 12128266 12128267\n",
      "300000 12174127 12174128\n",
      "400000 12219600 12219601\n",
      "0 12240767 12240768\n",
      "100000 12286150 12286151\n",
      "200000 12331532 12331533\n",
      "300000 12376720 12376721\n",
      "400000 12421943 12421944\n",
      "0 12442508 12442509\n",
      "100000 12487100 12487101\n",
      "200000 12531844 12531845\n",
      "300000 12576690 12576691\n",
      "400000 12621257 12621258\n",
      "0 12635326 12635327\n",
      "100000 12679933 12679934\n",
      "200000 12724475 12724476\n",
      "300000 12769122 12769123\n",
      "400000 12813480 12813481\n",
      "0 12822415 12822416\n",
      "100000 12866702 12866703\n",
      "200000 12910728 12910729\n",
      "300000 12954813 12954814\n",
      "400000 12998599 12998600\n",
      "0 13016037 13016038\n",
      "100000 13059889 13059890\n",
      "200000 13103830 13103831\n",
      "300000 13147785 13147786\n",
      "400000 13191539 13191540\n",
      "0 13211530 13211531\n",
      "100000 13255115 13255116\n",
      "200000 13298504 13298505\n",
      "300000 13341885 13341886\n",
      "400000 13385523 13385524\n",
      "0 13398750 13398751\n",
      "100000 13442342 13442343\n",
      "200000 13485771 13485772\n",
      "300000 13529136 13529137\n",
      "400000 13572170 13572171\n",
      "0 13583669 13583670\n",
      "100000 13626520 13626521\n",
      "200000 13669371 13669372\n",
      "300000 13712142 13712143\n",
      "400000 13754984 13754985\n",
      "0 13763812 13763813\n",
      "100000 13806464 13806465\n",
      "200000 13849138 13849139\n",
      "300000 13891353 13891354\n",
      "400000 13933754 13933755\n",
      "0 13955133 13955134\n",
      "100000 13997828 13997829\n",
      "200000 14040339 14040340\n",
      "300000 14082526 14082527\n",
      "400000 14124876 14124877\n",
      "0 14143920 14143921\n",
      "100000 14186205 14186206\n",
      "200000 14228222 14228223\n",
      "300000 14270028 14270029\n",
      "400000 14311939 14311940\n",
      "0 14321327 14321328\n",
      "100000 14363098 14363099\n",
      "200000 14404983 14404984\n",
      "300000 14446408 14446409\n",
      "400000 14487881 14487882\n",
      "0 14496990 14496991\n",
      "100000 14538638 14538639\n",
      "200000 14579922 14579923\n",
      "300000 14621447 14621448\n",
      "400000 14662780 14662781\n",
      "0 14681638 14681639\n",
      "100000 14722693 14722694\n",
      "200000 14763641 14763642\n",
      "300000 14804998 14804999\n",
      "400000 14846367 14846368\n",
      "0 14860580 14860581\n",
      "100000 14901365 14901366\n",
      "200000 14942530 14942531\n",
      "300000 14983032 14983033\n",
      "400000 15023899 15023900\n",
      "0 15034301 15034302\n",
      "100000 15074930 15074931\n",
      "200000 15115574 15115575\n",
      "300000 15156235 15156236\n",
      "400000 15196802 15196803\n",
      "0 15212498 15212499\n",
      "100000 15253040 15253041\n",
      "200000 15293402 15293403\n",
      "300000 15333674 15333675\n",
      "400000 15373912 15373913\n",
      "0 15391296 15391297\n",
      "100000 15431413 15431414\n",
      "200000 15471406 15471407\n",
      "300000 15511328 15511329\n",
      "400000 15551041 15551042\n",
      "0 15563399 15563400\n",
      "100000 15603305 15603306\n",
      "200000 15643246 15643247\n",
      "300000 15683235 15683236\n",
      "400000 15722959 15722960\n",
      "0 15728926 15728927\n",
      "100000 15768640 15768641\n",
      "200000 15808308 15808309\n",
      "300000 15848125 15848126\n",
      "400000 15887727 15887728\n",
      "0 15910258 15910259\n",
      "100000 15949689 15949690\n",
      "200000 15989097 15989098\n",
      "300000 16028433 16028434\n",
      "400000 16068045 16068046\n",
      "0 16077069 16077070\n",
      "100000 16115992 16115993\n",
      "200000 16155281 16155282\n",
      "300000 16194781 16194782\n",
      "0 16232149 16232150\n",
      "100000 16271317 16271318\n",
      "200000 16310112 16310113\n",
      "300000 16348975 16348976\n",
      "400000 16387799 16387800\n",
      "0 16412847 16412848\n",
      "100000 16451700 16451701\n",
      "200000 16490311 16490312\n",
      "300000 16528905 16528906\n",
      "400000 16567314 16567315\n",
      "0 16587689 16587690\n",
      "100000 16626483 16626484\n",
      "200000 16664715 16664716\n",
      "300000 16702832 16702833\n",
      "400000 16741206 16741207\n",
      "0 16751350 16751351\n",
      "100000 16802002 16802003\n",
      "200000 16848012 16848013\n",
      "300000 16893249 16893250\n",
      "400000 16937636 16937637\n",
      "500000 16981423 16981424\n",
      "600000 17024641 17024642\n",
      "700000 17067571 17067572\n",
      "800000 17109595 17109596\n",
      "900000 17151355 17151356\n"
     ]
    }
   ],
   "source": [
    "create_train_test_files(validation_files=5)\n",
    "# create_files_for_publisher(publisher_c29)\n",
    "# create_files_for_publisher(publisher_f8a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USER='Test'\n"
     ]
    }
   ],
   "source": [
    "import xlearn as xl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%env  USER = 'Test'\n",
    "os.environ['USER'] = 'test'\n",
    "# create ffm model\n",
    "ffm_model = xl.create_ffm() \n",
    "\n",
    "# set training and validation data\n",
    "ffm_model.setTrain(\"train.libffm\")\n",
    "ffm_model.setValidate(\"valid.libffm\")\n",
    "\n",
    "ffm_model.setOnDisk()\n",
    "\n",
    "# define params\n",
    "param = {'task':'binary', \n",
    "         'lr':0.2, \n",
    "         'k':4,\n",
    "                 'lambda':0.0002, \n",
    "                 'metric':'auc', \n",
    "                 'epoch': 100}\n",
    "\n",
    "# train the model\n",
    "ffm_model.fit(param, 'xl.out')\n",
    "\n",
    "# set the test data\n",
    "ffm_model.setTest(\"test.libffm\")\n",
    "ffm_model.setSigmoid()\n",
    "\n",
    "# # make predictions\n",
    "ffm_model.predict(\"xl.out\", \"output.txt\")\n",
    "\n",
    "# create submission file\n",
    "# sample = pd.read_csv('sample_submission.csv')\n",
    "# output = pd.read_csv('output.txt', header=None)[0].values\n",
    "# sample.HasDetections = output\n",
    "# sample.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the test data\n",
    "ffm_model.setTest(\"test.libffm\")\n",
    "ffm_model.setSigmoid()\n",
    "\n",
    "# make predictions\n",
    "ffm_model.predict(\"xl.out\", \"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./for_submission.csv', header=None, names=['Predicted']).to_csv('./submission.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1584202133282,
     "user": {
      "displayName": "Guy Gonen",
      "photoUrl": "",
      "userId": "13001566563642212261"
     },
     "user_tz": -120
    },
    "id": "pkhbSTMCDWGd",
    "outputId": "00843923-1ca7-478a-f4b0-8f824cea67e0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "FILES_LIMIT = 1\n",
    "\n",
    "all_files = glob.glob('./data/train/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for index, filename in enumerate(all_files):\n",
    "    df = pd.read_csv(filename)#, usecols=['user_id_hash', 'target_id_hash', 'is_click'])\n",
    "    li.append(df)\n",
    "    \n",
    "    if index > FILES_LIMIT:\n",
    "        break\n",
    "\n",
    "train = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# train = pd.concat(map(pd.read_csv, glob.glob('./data/train/*.csv')))\n",
    "# train = pd.read_csv('./data/train1/part-00000.csv')\n",
    "\n",
    "test = pd.read_csv('./data/test_file_v3/test_file.csv')\n",
    "# train.dropna(inplace=True) # This is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise model: SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SurpriseSVDPlusPlus(train, test)\n",
    "algo = svd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.prediction_algorithms.matrix_factorization.SVDpp object at 0x7f7202d0dcf8>\n"
     ]
    }
   ],
   "source": [
    "print(algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n"
     ]
    }
   ],
   "source": [
    "estimations = np.zeros((len(test)))\n",
    "\n",
    "for index, row in enumerate(test.itertuples()):\n",
    "    estimations[index] = algo.predict(row.user_id_hash, row.target_id_hash).est\n",
    "    if (index % 100000) == 0 :\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Predicted'] = estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Predicted']].to_csv('./submission.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise Model: SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2774\n",
      "MAE:  1.0178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0178469771834977"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SurpriseSVDPlusPlus(train, test)\n",
    "svd.train()\n",
    "svd.predictRating()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "Take all the former models and try to average all the scores in order to create a more robust model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "df = None\n",
    "for x in glob.glob('./**/submission.csv', recursive=True):\n",
    "    if df is None:\n",
    "        df = pd.read_csv(x)\n",
    "    else:\n",
    "        df = pd.merge(df, pd.read_csv(x), on = \"Id\")\n",
    "\n",
    "feature_vector = df.drop(['Id'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector['Predicted'] = feature_vector.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector['Predicted'].to_csv('./submission.csv', index_label='Id', %%writefileader=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/test_file_v3/test_file.csv'\n",
    "test_df  = pd.read_csv(train_path, usecols=['publisher_id_hash'])\n",
    "\n",
    "publisher_848 =  '848b127dbd0f3a647581f4a95325f5204f4577ad7956f6ccaee6bf1eec0c399e6b02015827a95741ae041adc2438fbd494076ece7796a5f6cf4eab29e1079cf3'\n",
    "publisher_c29 = 'c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f024944fbd55d0ecbec178d4fc94c38d88a56a177a1c302f47ac1293dbbed50638455d50b1769daedbd33aaf'\n",
    "publisher_f8a = 'f8a7ba9b7c9b05464ee98daac522b3f3d2376453c70e57de45b65e65a06b3b45fedd82ec18291bb4e432f3a172893424a81bab47dad1b4355b68552cda00583a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = pd.read_csv('./models/on_65_files_85819/for_submission.csv', header=None, names=['Predicted'])\n",
    "pub_top = pd.read_csv('./models/top_pub/for_submission.csv', header=None, names=['Predicted'])\n",
    "pub_f8a7b = pd.read_csv('./for_submission_f8a7b.csv', header=None, names=['Predicted'])\n",
    "pub_c29 = pd.read_csv('./for_submission_c29a9.csv', header=None, names=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1          True\n",
       "2          True\n",
       "3         False\n",
       "4         False\n",
       "          ...  \n",
       "999523     True\n",
       "999524    False\n",
       "999525    False\n",
       "999526    False\n",
       "999527    False\n",
       "Name: publisher_id_hash, Length: 999528, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df.loc[test_df['publisher_id_hash'] == publisher_f8a,:] = pub_f8a7b[test_df['publisher_id_hash'] == publisher_f8a].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df.loc[test_df['publisher_id_hash'] == publisher_848,:] = pub_top[test_df['publisher_id_hash'] == publisher_848].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df.to_csv('./submission.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f02494...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f8a7ba9b7c9b05464ee98daac522b3f3d2376453c70e57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f8a7ba9b7c9b05464ee98daac522b3f3d2376453c70e57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f02494...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848b127dbd0f3a647581f4a95325f5204f4577ad7956f6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999523</th>\n",
       "      <td>f8a7ba9b7c9b05464ee98daac522b3f3d2376453c70e57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999524</th>\n",
       "      <td>848b127dbd0f3a647581f4a95325f5204f4577ad7956f6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999525</th>\n",
       "      <td>c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f02494...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999526</th>\n",
       "      <td>c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f02494...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999527</th>\n",
       "      <td>848b127dbd0f3a647581f4a95325f5204f4577ad7956f6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999528 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        publisher_id_hash\n",
       "0       c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f02494...\n",
       "1       f8a7ba9b7c9b05464ee98daac522b3f3d2376453c70e57...\n",
       "2       f8a7ba9b7c9b05464ee98daac522b3f3d2376453c70e57...\n",
       "3       c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f02494...\n",
       "4       848b127dbd0f3a647581f4a95325f5204f4577ad7956f6...\n",
       "...                                                   ...\n",
       "999523  f8a7ba9b7c9b05464ee98daac522b3f3d2376453c70e57...\n",
       "999524  848b127dbd0f3a647581f4a95325f5204f4577ad7956f6...\n",
       "999525  c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f02494...\n",
       "999526  c29a980222a2a97b74ffbd067f2a4ce760e3e8d8f02494...\n",
       "999527  848b127dbd0f3a647581f4a95325f5204f4577ad7956f6...\n",
       "\n",
       "[999528 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BUSINESS~PERSONAL'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = 'BUSINESS~PERSONAL~FINANCE'\n",
    "category[:category.rfind('~')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields user_id_hash, target_id_hash, syndicator_id_hash, campaign_id_hash, target_item_taxonomy, placement_id_hash, publisher_id_hash, source_id_hash, source_item_type, browser_platform, country_code, region",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e38fe391394c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dask_xgboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, classes, eval_set, sample_weight_eval_set, eval_metric, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         )\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dask_xgboost/core.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(client, params, data, labels, dmatrix_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \"\"\"\n\u001b[1;32m    241\u001b[0m     return client.sync(\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0m_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmatrix_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             return sync(\n\u001b[0;32m--> 767\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m             )\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhad_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mexc_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m                             \u001b[0myielded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m                         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                             \u001b[0;31m# Break up a reference to itself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dask_xgboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(client, params, data, labels, dmatrix_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# Get the results, only one will be non-None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhad_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1726\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1728\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1729\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dask_xgboost/core.py\u001b[0m in \u001b[0;36mtrain_part\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mdmatrix_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdmatrix_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     evals = _package_evals(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    378\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    379\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[1;32m    238\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields user_id_hash, target_id_hash, syndicator_id_hash, campaign_id_hash, target_item_taxonomy, placement_id_hash, publisher_id_hash, source_id_hash, source_item_type, browser_platform, country_code, region"
     ]
    }
   ],
   "source": [
    "from dask_ml.xgboost import XGBClassifier\n",
    "from distributed import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "train, test = df.random_split([0.8, 0.2])\n",
    "\n",
    "train_labels = train['is_click']\n",
    "test_labels = test['is_click']\n",
    "\n",
    "del train['is_click']  # remove informative column from data\n",
    "del test['is_click']  # remove informative column from data\n",
    "\n",
    "est = XGBClassifier(num_class=2, verbose_eval=True, silent=False)\n",
    "est.fit(train, train_labels)\n",
    "\n",
    "prediction = est.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.312, 23.12 , 43.1  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply([0.12312, 0.2312, 0.431], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.05050505, 0.1010101 , 0.15151515, 0.2020202 ,\n",
       "       0.25252525, 0.3030303 , 0.35353535, 0.4040404 , 0.45454545,\n",
       "       0.50505051, 0.55555556, 0.60606061, 0.65656566, 0.70707071,\n",
       "       0.75757576, 0.80808081, 0.85858586, 0.90909091, 0.95959596,\n",
       "       1.01010101, 1.06060606, 1.11111111, 1.16161616, 1.21212121,\n",
       "       1.26262626, 1.31313131, 1.36363636, 1.41414141, 1.46464646,\n",
       "       1.51515152, 1.56565657, 1.61616162, 1.66666667, 1.71717172,\n",
       "       1.76767677, 1.81818182, 1.86868687, 1.91919192, 1.96969697,\n",
       "       2.02020202, 2.07070707, 2.12121212, 2.17171717, 2.22222222,\n",
       "       2.27272727, 2.32323232, 2.37373737, 2.42424242, 2.47474747,\n",
       "       2.52525253, 2.57575758, 2.62626263, 2.67676768, 2.72727273,\n",
       "       2.77777778, 2.82828283, 2.87878788, 2.92929293, 2.97979798,\n",
       "       3.03030303, 3.08080808, 3.13131313, 3.18181818, 3.23232323,\n",
       "       3.28282828, 3.33333333, 3.38383838, 3.43434343, 3.48484848,\n",
       "       3.53535354, 3.58585859, 3.63636364, 3.68686869, 3.73737374,\n",
       "       3.78787879, 3.83838384, 3.88888889, 3.93939394, 3.98989899,\n",
       "       4.04040404, 4.09090909, 4.14141414, 4.19191919, 4.24242424,\n",
       "       4.29292929, 4.34343434, 4.39393939, 4.44444444, 4.49494949,\n",
       "       4.54545455, 4.5959596 , 4.64646465, 4.6969697 , 4.74747475,\n",
       "       4.7979798 , 4.84848485, 4.8989899 , 4.94949495, 5.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def bucket_ctr_feature(feature):\n",
    "    buckets = np.linspace(0, 5, 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files_for_publisher(publisher, how_many_files=None):\n",
    "    dont_use = ['page_view_start_time', 'gmt_offset', 'publisher_id_hash']\n",
    "    categories = [k for k, v in dtypes.items() if k not in dont_use]\n",
    "    categories_index = dict(zip(categories, range(len(categories))))\n",
    "    field_features = defaultdict()\n",
    "\n",
    "    max_val = 1\n",
    "    for index, file in enumerate(glob.glob('./data/train/*.csv')):\n",
    "        main_libffm = 'train_%s.libffm' % publisher[:5]\n",
    "        if index > 60:\n",
    "            main_libffm = 'valid_%s.libffm' % publisher[:5]\n",
    "\n",
    "        with open(main_libffm, 'a') as the_file:\n",
    "            for t, row in enumerate(DictReader(open(file))):\n",
    "                if t % 100000 == 0:\n",
    "                    print(t, len(field_features), max_val)\n",
    "\n",
    "                if row['publisher_id_hash'] !=  publisher:\n",
    "                    continue\n",
    "\n",
    "                label = [row['is_click']]\n",
    "                ffeatures = []\n",
    "                print(row)\n",
    "                for field in categories:\n",
    "                    if field == 'is_click':\n",
    "                        continue\n",
    "                    feature = row[field]\n",
    "\n",
    "                    if feature == '':\n",
    "                        feature = \"unk\"\n",
    "                    if field not in num_cols:\n",
    "                        ff = field + '_____' + feature\n",
    "                    else:\n",
    "                        if feature == \"unk\" or float(feature) == -1:\n",
    "                            ff = field + '_____' + str(0)\n",
    "                        else:\n",
    "                            if field in too_many_vals:\n",
    "                                ff = field + '_____' + str(int(round(math.log(1 + float(feature)))))\n",
    "                            else:\n",
    "                                ff = field + '_____' + str(int(round(float(feature))))\n",
    "                    if ff not in field_features:\n",
    "                        if len(field_features) == 0:\n",
    "                            field_features[ff] = 1\n",
    "                            max_val += 1\n",
    "                        else:\n",
    "                            field_features[ff] = max_val + 1\n",
    "                            max_val += 1\n",
    "\n",
    "                    fnum = field_features[ff]\n",
    "                    ffeatures.append('{}:{}:1'.format(categories_index[field], fnum))\n",
    "\n",
    "                \n",
    "                line = label + ffeatures\n",
    "                print(line)\n",
    "                print('{}\\n'.format(' '.join(line)))\n",
    "                print(field_features)\n",
    "                break\n",
    "                the_file.write('{}\\n'.format(' '.join(line)))\n",
    "            break\n",
    "        break\n",
    "\n",
    "                \n",
    "    train_path = './data/test_file_v3/test_file.csv'\n",
    "    with open('test_%s.libffm' % publisher[:5], 'a') as the_file:\n",
    "        for t, row in enumerate(DictReader(open(train_path))):\n",
    "            if t % 100000 == 0:\n",
    "                print(t, len(field_features), max_val)\n",
    "\n",
    "            label = ['0']\n",
    "            ffeatures = []\n",
    "\n",
    "            for field in categories:\n",
    "                if field == 'is_click':\n",
    "                    continue\n",
    "                feature = row[field]\n",
    "                if feature == '':\n",
    "                    feature = \"unk\"\n",
    "                if field not in num_cols:\n",
    "                    ff = field + '_____' + feature\n",
    "                else:\n",
    "                    if feature == \"unk\" or float(feature) == -1:\n",
    "                        ff = field + '_____' + str(0)\n",
    "                    else:\n",
    "                        if field in too_many_vals:\n",
    "                            ff = field + '_____' + str(int(round(math.log(1 + float(feature)))))\n",
    "                        else:\n",
    "                            ff = field + '_____' + str(int(round(float(feature))))\n",
    "                if ff not in field_features:\n",
    "                    if len(field_features) == 0:\n",
    "                        field_features[ff] = 1\n",
    "                        max_val += 1\n",
    "                    else:\n",
    "                        field_features[ff] = max_val + 1\n",
    "                        max_val += 1\n",
    "\n",
    "                fnum = field_features[ff]\n",
    "\n",
    "                ffeatures.append('{}:{}:1'.format(categories_index[field], fnum))\n",
    "            line = label + ffeatures\n",
    "            the_file.write('{}\\n'.format(' '.join(line)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPzSMgX5RKfRm2twFxtojYR",
   "collapsed_sections": [],
   "mount_file_id": "10jHTa8w_4YXDyxlzxbbXaimEO-26D80G",
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
